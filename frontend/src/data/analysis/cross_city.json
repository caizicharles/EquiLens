{
  "model": "claude-sonnet-4-6",
  "cross_city": {
    "demographic_only": {
      "summary": "Individual city assessments identify local risks, but a cross-city comparison reveals which bias signals are baked into the model itself versus which emerge from specific demographic compositions. This distinction is critical for prioritizing remediation: a model-level bias requires retraining, while a composition-dependent bias may be addressable through deployment-time guardrails.\n\nAll three cities — London (80/20 ethnicity, 60/40 gender, 90/10 SES), Edinburgh (90/10 ethnicity, 40/60 gender, 90/10 SES), and Dublin (90/10 ethnicity, 50/50 gender, 80/20 SES) — were evaluated on the same 10 clinical scenarios under the same 7 demographic framings, with city-level metrics weighted by each city's real demographic composition. Baseline accuracy was 0.90 across all conditions.",
      "findings": "The cross-city analysis reveals a model with one universal bias, one localized anomaly, and one clean dimension. Ethnicity is the universal signal: all three cities exhibit consistency ratios below 1.0 (London 0.875, Edinburgh 0.889, Dublin 0.889), confirming that Black demographic framing induces more behavioral instability than White framing — a model-intrinsic counterfactual fairness violation independent of city composition. The slight variation between London (0.875) and the other two cities (0.889) is attributable to London's higher Black composition (20% vs. 10%), which assigns more scenarios to the minority group and amplifies the measurable signal. Gender bias is localized exclusively to Edinburgh, where the consistency ratio of 1.200 indicates female-framed scenarios receive 20% less stable treatment than male-framed ones — the strongest single bias signal in the experiment. London and Dublin show perfect gender consistency (1.0), with Dublin's balanced 50/50 split providing the strongest evidence that the model does not have a broad gender bias. SES is entirely neutral across all cities and all compositions — spanning splits from 80/20 to 90/10 — confirming the model genuinely does not discriminate based on income level. Critically, no demographic framing degrades accuracy in any city (all accuracy ratios ≥1.0), meaning the bias manifests as differential behavioral stability rather than differential outcomes: the model does not give worse answers to minority groups, but it gives less reliable answers — a subtler but still meaningful fairness violation.",
      "recommendation": "Implement systematic counterfactual demographic augmentation across both ethnicity and gender dimensions — pairing every training scenario with race- and gender-swapped variants and applying a consistency regularization loss that penalizes differential answer-switching rates — to eliminate the universal ethnicity asymmetry (0.875–0.889) and Edinburgh's gender anomaly (1.200) at the model level. SES requires no remediation."
    },
    "disease_only": {
      "summary": "A model that performs well in Edinburgh but poorly in Dublin is not a good model deployed in the right city — it is a model whose competence happens to align with one city's disease profile and not another's. Cross-city comparison exposes whether performance differences are model-level (shared weaknesses in certain medical domains) or city-specific (driven by the particular disease mix), and determines whether deployment viability is genuinely generalizable or merely coincidental.\n\nAll three cities — London (cancer 53.4%, cardiovascular 22.0%, dementia/neuro 24.6%), Edinburgh (cancer 54.4%, cardiovascular 23.9%, respiratory 21.7%), and Dublin (cancer 42.5%, cardiovascular 39.7%, respiratory 17.8%) — were evaluated on 100 clinical scenarios each, sampled proportionally to real-world disease prevalence. Performance was measured via accuracy and macro F1 at both aggregate and per-disease levels.",
      "findings": "The cross-city analysis reveals a model with strong but fundamentally uneven clinical competence, where deployment viability depends heavily on whether a city's disease burden aligns with the model's domain strengths. Cancer is the universal strength: accuracy ranges from 88.4% to 98.1% across all cities, consistently the best or tied-best domain everywhere, suggesting robust oncology training representation. Respiratory and neurology are universal weaknesses: wherever these domains appear, they form the weakest category — respiratory at 75.0% (Dublin) and 86.4% (Edinburgh), dementia/neuro at 66.7% (London) — suggesting the model has seen substantially less respiratory and neurology content during training. Edinburgh emerges as the strongest city (94.0% aggregate, 9.8-point spread) largely because its disease burden is heaviest in the model's strong domains; this is a composition advantage, not a competence one. London has the most dangerous single gap: the 66.7% dementia/neuro accuracy creates a 31.4-point within-city spread and accounts for 24.6% of its disease burden, making London's aggregate of 89.8% deeply misleading. Dublin has the most uniformly weak profile: every disease domain trails the other cities by 8–11 points, with an aggregate of 85.0% — a pattern suggesting the model is poorly calibrated to Dublin-relevant clinical content rather than failing in one specific area. Aggregate accuracy alone is insufficient for deployment decisions; London's 89.8% looks reasonable but conceals a 66.7% floor, while Edinburgh's 94.0% is genuinely strong across the board.",
      "recommendation": "Prioritize domain-specific enrichment targeting the three weakest areas: neurology/dementia (London-critical, 66.7%), respiratory medicine (Dublin/Edinburgh-relevant, 75.0%–86.4%), and Dublin-relevant cardiovascular subtopics (85.4% against a 39.7% composition weight). The curriculum should aim to flatten the 9–31 point cross-domain accuracy gaps that currently make deployment viability city-dependent, bringing all disease domains above 90%."
    },
    "combined": {
      "summary": "Comparing all three cities side-by-side reveals both shared vulnerabilities and city-specific risk profiles.",
      "findings": "The cross-city analysis reveals a model with strong but uneven clinical competence and a consistent low-grade ethnicity bias. The shared ethnicity consistency ratio below 1.0 (0.875–0.889) across all three cities confirms that demographic framing with Black racial cues induces more behavioral instability than White cues — a model-intrinsic bias rather than a sampling artifact. SES framing is reassuringly neutral across all cities. The disease-domain results paint a more differentiated picture: Edinburgh emerges as clearly strongest (94.0% accuracy, 9.8-point spread), London is compromised by a catastrophic dementia/neuro gap (66.7%, 31.4-point spread), and Dublin shows systematically depressed performance across all domains (85.0% aggregate). The model's demonstrated strength in oncology (88.4%–98.1%) contrasts sharply with its weakness in respiratory (75.0%–86.4%) and neurological (66.7%) medicine, suggesting uneven training representation. Taken together, these findings indicate that deployment viability is highly city-dependent, driven primarily by whether a city's disease burden aligns with the model's domain strengths or weaknesses.",
      "recommendation": "Prioritize a two-pronged retraining strategy: (1) domain-specific enrichment targeting neurology/dementia, respiratory medicine, and Dublin-relevant cardiovascular subtopics to flatten the 9–31 point cross-domain accuracy gaps that make deployment viability city-dependent; and (2) systematic counterfactual demographic augmentation across ethnicity and gender dimensions — pairing every training question with race- and gender-swapped variants and applying consistency regularization loss — to eliminate the universal ethnicity consistency asymmetry and Edinburgh's gender anomaly at the model level rather than per-city."
    }
  }
}
